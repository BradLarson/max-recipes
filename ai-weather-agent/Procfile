max-serve-llm: (magic global install max-pipelines && magic global update max-pipelines) || true; MAX_SERVE_PORT=8000 MAX_SERVE_HOST=localhost HUGGING_FACE_HUB_TOKEN=$(cat backend/.env | grep HUGGING_FACE_HUB_TOKEN | cut -d '=' -f2) max-pipelines serve --huggingface-repo-id=modularai/Llama-3.1-8B-Instruct-GGUF --max-length 2048
max-serve-embedding: (magic global install max-pipelines && magic global update max-pipelines) || true; MAX_SERVE_PORT=7999 MAX_SERVE_HOST=localhost HUGGING_FACE_HUB_TOKEN=$(cat backend/.env | grep HUGGING_FACE_HUB_TOKEN | cut -d '=' -f2) max-pipelines serve --huggingface-repo-id=sentence-transformers/all-mpnet-base-v2
backend: cd backend && magic run backend
frontend: cd frontend && magic run frontend
