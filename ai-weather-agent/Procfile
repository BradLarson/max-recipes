llm: magic global install max-pipelines && magic global update max-pipelines && max-pipelines serve --huggingface-repo-id=modularai/Llama-3.1-8B-Instruct-GGUF --max-length 2048
backend: cd backend && magic run backend
frontend: cd frontend && magic run frontend
